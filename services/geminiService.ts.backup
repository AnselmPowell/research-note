
import { GoogleGenAI } from "@google/genai";
import { SearchResultData, SearchSource, DeepResearchNote, ArxivPaper, ArxivSearchStructured } from "../types";
import { config } from "../config/env";

// Configuration for Google Programmable Search Engine
const GOOGLE_SEARCH_KEY = config.googleSearchKey;
const GOOGLE_SEARCH_CX = config.googleSearchCx;

// OpenAI Fallback Configuration
const OPENAI_API_KEY = config.openaiApiKey;

// Initialize Gemini AI with graceful degradation
let ai: GoogleGenAI | null = null;

try {
  if (config.geminiApiKey && config.geminiApiKey !== '') {
    ai = new GoogleGenAI({ apiKey: config.geminiApiKey });
  } else {
    console.warn('[GeminiService] API key missing - AI features will be limited');
  }
} catch (error) {
  console.error('[GeminiService] Failed to initialize Gemini AI:', error);
  ai = null;
}

// Helper for delays
const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

// Simple In-Memory Cache for Embeddings to save API calls
const embeddingCache = new Map<string, number[]>();

/**
 * Shared Async Pool Utility
 * Controls concurrency for any list of async tasks.
 */
async function asyncPool<T, R>(concurrency: number, items: T[], worker: (item: T) => Promise<R>): Promise<R[]> {
  const results: R[] = new Array(items.length);
  let i = 0;

  async function runNext() {
      const index = i++;
      if (index >= items.length) return;
      
      try {
          results[index] = await worker(items[index]);
      } catch (err) {
          console.warn(`Pool worker failed at index ${index}`, err);
          // @ts-ignore
          results[index] = null; 
      }
      
      return runNext();
  }

  const workers = Array.from({ length: Math.min(concurrency, items.length) }, () => runNext());
  await Promise.all(workers);
  return results;
}

const cleanJson = (text: string) => {
  return text.replace(/```json/g, "").replace(/```/g, "").trim();
};

/**
 * Shared OpenAI Call Utility
 */
async function callOpenAI(prompt: string): Promise<any> {
  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [
          {
            role: "system",
            content: "You are a precise research analyst helper. Output valid JSON only."
          },
          {
            role: "user",
            content: prompt
          }
        ],
        response_format: { type: "json_object" }
      })
    });

    if (!response.ok) {
       const err = await response.text();
       throw new Error(`OpenAI Error: ${response.status} - ${err}`);
    }

    const data = await response.json();
    const content = data.choices[0]?.message?.content;
    return content ? JSON.parse(content) : [];
  } catch (error) {
    console.error("[LLM] OpenAI Fallback Failed:", error);
    throw error;
  }
}

/**
 * Uses Gemini to generate 5 distinct, effective search queries for finding PDFs
 */ 
export const enhanceMetadataWithAI = async (
  firstFourPagesText: string,
  currentMetadata: { title: string; author: string; subject: string },
  signal?: AbortSignal
): Promise<{ title: string; author: string; subject: string }> => {
  
  // Check abort before starting
  if (signal?.aborted) throw new Error('Aborted');
  
  const prompt = `You are analyzing the first 4 pages of a research paper to extract missing metadata.

Current metadata:
- Title: ${currentMetadata.title}
- Author: ${currentMetadata.author} 
- Subject: ${currentMetadata.subject}

Text from first 4 pages:
${firstFourPagesText}

Extract the title, author(s), and subject/abstract from this text. Return as JSON:
{
  "title": "exact paper title found in the text",
  "author": "main author or first author listed", 
  "subject": "brief abstract or subject description"
}

If you cannot find clear information for any field, return the current value for that field.`;

  try {
    if (!ai) {
      console.warn('[MetadataEnhancement] Gemini AI not available - using fallback OpenAI');
      throw new Error('Gemini AI not initialized');
    }
    
    // Check abort before AI call
    if (signal?.aborted) throw new Error('Aborted');
    
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: prompt,
      config: { responseMimeType: "application/json" }
    });
    
    // Check abort after AI call
    if (signal?.aborted) throw new Error('Aborted');
    
    const text = response.text;
    if (text) {
      const enhanced = JSON.parse(cleanJson(text));
      return {
        title: enhanced.title || currentMetadata.title,
        author: enhanced.author || currentMetadata.author,
        subject: enhanced.subject || currentMetadata.subject
      };
    }
  } catch (error: any) {
    if (error.message === 'Aborted') throw error; // Re-throw abort
    
    console.warn(`[MetadataEnhancement] Gemini failed. Switching to OpenAI.`);
    
    // Try OpenAI fallback
    try {
      if (signal?.aborted) throw new Error('Aborted');
      
      if (OPENAI_API_KEY) {
        const result = await callOpenAI(prompt);
        
        if (signal?.aborted) throw new Error('Aborted');
        
        return {
          title: result.title || currentMetadata.title,
          author: result.author || currentMetadata.author,
          subject: result.subject || currentMetadata.subject
        };
      }
    } catch (err: any) {
      if (err.message === 'Aborted') throw err;
      console.error('[MetadataEnhancement] OpenAI fallback failed:', err);
    }
  }

  // Fallback: return current metadata if all AI calls fail
  return currentMetadata;
};

export const generateSearchVariations = async (originalQuery: string): Promise<string[]> => {
  const model = "gemini-2.5-flash";
  const prompt = `You are a research assistant. The user is looking for PDF documents/papers about: "${originalQuery}".
  Generate 5 additional, distinct, simple keyword-based search queries to find relevant research PDFs.
  Do not use boolean operators like OR/AND. Keep them simple and targeted.
  Return ONLY the queries as a JSON array of strings.`;

  try {
    if (!ai) {
      console.warn('[GeminiService] Gemini AI not available - using fallback OpenAI');
      throw new Error('Gemini AI not initialized');
    }
    
    const response = await ai.models.generateContent({
      model: model,
      contents: prompt,
      config: { responseMimeType: "application/json" }
    });
    const text = response.text;
    if (text) {
      const queries = JSON.parse(cleanJson(text));
      return Array.isArray(queries) ? queries : [];
    }
  } catch (error: any) {
    console.warn(`[Search Vars] Gemini failed. Switching to OpenAI.`);
  }

  // Fallback to OpenAI or simple variations if both fail
  try {
     if (OPENAI_API_KEY) {
       const result = await callOpenAI(prompt);
       if (Array.isArray(result)) return result;
       if (result.queries && Array.isArray(result.queries)) return result.queries;
     }
  } catch (err) {
     // If both AI services fail, return simple variations
     console.warn('[Search Vars] Both AI services failed - using simple fallback');
  }

  // Simple fallback - return variations of the original query
  return [
    `${originalQuery} research`,
    `${originalQuery} study`,
    `${originalQuery} analysis`,
    `${originalQuery} paper`,
    `${originalQuery} academic`
  ];
};

/**
 * Step 1: Generate Optimized Arxiv Keywords
 */
export const generateArxivSearchTerms = async (topics: string[], questions: string[]): Promise<ArxivSearchStructured> => {
  const fallback: ArxivSearchStructured = {
    exact_phrases: [],
    title_terms: topics.slice(0, 3),
    abstract_terms: [],
    general_terms: topics.slice(0, 3)
  };

  const context = `
    RESEARCH TOPICS: ${topics.join(", ")}
    SPECIFIC RESEARCH QUESTIONS:
    ${questions.map(q => `- ${q}`).join("\n")}
  `;
  
  const prompt = `
    You are an arXiv search expert.
    User Topic: "${topics.join(", ")}"
    User Questions: "${questions.join("; ")}"

    ### CORE INSTRUCTION: ANCHORING ###
    You must ANCHOR every generated search term to the main subject ("${topics[0] || 'the topic'}").
    
    ### RULES ###
    1. **NO GENERIC WORDS**: Never use words like "benefits", "issues", "impact", "performance", "metrics" on their own. 
    2. **exact_phrases** (2-4 words): Highly specific phrases.
    3. **title_terms** (2-4 words): Terms that appear in Titles. 
    4. **abstract_terms** (1-2 words): We combine these with AND. 
    5. **general_terms** (2-3 words): Domain synonyms. 

    Return valid JSON matching this structure:
    {
      "exact_phrases": ["string", "string"],
      "title_terms": ["string", "string"],
      "abstract_terms": ["string", "string", "string"],
      "general_terms": ["string", "string"]
    }

    6. A MAX of 8 search terms must be returned.
  `;

  try {
    if (!ai) {
      console.warn('[ArXiv Gen] Gemini AI not available - using fallback');
      throw new Error('Gemini AI not initialized');
    }
    
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: prompt,
      config: { responseMimeType: "application/json" }
    });
    
    if (response.text) {
      const result = JSON.parse(cleanJson(response.text));
      return validateArxivResult(result, fallback);
    }
  } catch (error: any) {
    console.warn(`[ArXiv Gen] Gemini Failed. Message: ${error.message?.slice(0, 100)}...`);
  }

  try {
    if (OPENAI_API_KEY) {
      const result = await callOpenAI(prompt);
      return validateArxivResult(result, fallback);
    }
  } catch (error) {
    console.warn('[ArXiv Gen] OpenAI also failed - using fallback terms');
  }

  return fallback;
};

function validateArxivResult(result: any, fallback: ArxivSearchStructured): ArxivSearchStructured {
  if (result && typeof result === 'object') {
    return {
      exact_phrases: Array.isArray(result.exact_phrases) ? result.exact_phrases : [],
      title_terms: Array.isArray(result.title_terms) ? result.title_terms : [],
      abstract_terms: Array.isArray(result.abstract_terms) ? result.abstract_terms : [],
      general_terms: Array.isArray(result.general_terms) ? result.general_terms : []
    };
  }
  return fallback;
}

export const generateInsightQueries = async (userQuestions: string, contextQuery: string): Promise<string[]> => {
  const prompt = `Context: The user has gathered several academic PDF papers regarding "${contextQuery}".
  User Goal: They want to answer the following specific questions from these papers: "${userQuestions}".
  Task: Generate 5 semantic search phrases or short questions.
  Return ONLY the 5 phrases as a JSON array of strings.`;

  try {
    if (!ai) {
      console.warn('[Insight Gen] Gemini AI not available - using fallback');
      throw new Error('Gemini AI not initialized');
    }
    
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: prompt,
      config: { responseMimeType: "application/json" }
    });
    if (response.text) {
      const queries = JSON.parse(cleanJson(response.text));
      return Array.isArray(queries) ? queries : [];
    }
  } catch (error) {
    console.warn(`[Insight Gen] Gemini failed. Switching to OpenAI.`);
  }

  try {
     if (OPENAI_API_KEY) {
       const result = await callOpenAI(prompt);
       if (Array.isArray(result)) return result;
       if (result.queries && Array.isArray(result.queries)) return result.queries;
     }
  } catch (e) {
     console.warn('[Insight Gen] OpenAI also failed - using simple fallback');
  }

  // Simple fallback if both AI services fail
  return [userQuestions];
};

function cosineSimilarity(vecA: number[], vecB: number[]): number {
  const dotProduct = vecA.reduce((acc, val, i) => acc + val * vecB[i], 0);
  const magnitudeA = Math.sqrt(vecA.reduce((acc, val) => acc + val * val, 0));
  const magnitudeB = Math.sqrt(vecB.reduce((acc, val) => acc + val * val, 0));
  if (magnitudeA === 0 || magnitudeB === 0) return 0;
  return dotProduct / (magnitudeA * magnitudeB);
}

async function getEmbedding(text: string, taskType: string = "RETRIEVAL_DOCUMENT", retries = 3): Promise<number[]> {
  if (!ai || !config.geminiApiKey) {
    console.warn('[Embeddings] Gemini AI not available - returning empty vector');
    return [];
  }

  const cacheKey = `${taskType}:${text.trim()}`;
  if (embeddingCache.has(cacheKey)) {
    return embeddingCache.get(cacheKey)!;
  }

  for (let attempt = 0; attempt < retries; attempt++) {
    try {
      const result = await ai.models.embedContent({
        model: "text-embedding-004",
        contents: { parts: [{ text: text }] },
        config: {
            taskType: taskType as any
        }
      });
      const vec = result.embeddings?.[0]?.values || [];
      if (vec.length > 0) embeddingCache.set(cacheKey, vec);
      return vec;
    } catch (error: any) {
      const isRateLimit = error?.message?.includes('429') || error?.status === 429 || error?.code === 429;
      const isServerOverload = error?.status === 503;

      if ((isRateLimit || isServerOverload) && attempt < retries - 1) {
        const backoffTime = Math.pow(2, attempt) * 2000 + (Math.random() * 1000);
        await delay(backoffTime);
        continue;
      }
      
      if (attempt === retries - 1) return [];
    }
  }
  return [];
}

async function getBatchEmbeddings(texts: string[], taskType: string = "RETRIEVAL_DOCUMENT"): Promise<number[][]> {
  if (texts.length === 0) return [];
  
  if (!ai || !config.geminiApiKey) {
    console.warn('[Batch Embeddings] Gemini AI not available - returning empty vectors');
    return texts.map(() => []);
  }
  
  const results: number[][] = new Array(texts.length).fill([]);
  const uncachedIndices: number[] = [];
  const uncachedTexts: string[] = [];

  texts.forEach((text, i) => {
    const key = `${taskType}:${text.trim()}`;
    if (embeddingCache.has(key)) {
      results[i] = embeddingCache.get(key)!;
    } else {
      uncachedIndices.push(i);
      uncachedTexts.push(text);
    }
  });

  if (uncachedTexts.length === 0) return results;

  const BATCH_SIZE = 50; 
  const batches = [];
  
  for (let i = 0; i < uncachedTexts.length; i += BATCH_SIZE) {
    batches.push({
      texts: uncachedTexts.slice(i, i + BATCH_SIZE),
      indices: uncachedIndices.slice(i, i + BATCH_SIZE)
    });
  }

  await asyncPool(3, batches, async (batch) => {
    const requests = batch.texts.map(t => ({
      model: "models/text-embedding-004",
      content: { parts: [{ text: t }] },
      taskType: taskType
    }));

    let batchSuccess = false;
    let batchEmbeddings: number[][] = [];

    for (let attempt = 0; attempt < 4; attempt++) {
      try {
        const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents?key=${config.geminiApiKey}`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({ requests })
        });

        if (!response.ok) {
            if (response.status === 429 || response.status === 503) {
                const text = await response.text();
                throw new Error(`Rate Limit: ${text}`);
            }
            throw new Error(`HTTP Error ${response.status}`);
        }

        const data = await response.json();

        if (data.embeddings) {
           batchEmbeddings = data.embeddings.map((e: any) => e.values || []);
           if (batchEmbeddings.length !== requests.length) throw new Error("Alignment mismatch");
           batchSuccess = true;
           break;
        } else {
           throw new Error("No embeddings");
        }
      } catch (err: any) {
        if (err.message?.includes('Rate Limit') || attempt < 3) {
           const backoff = Math.pow(2, attempt) * 2000 + (Math.random() * 1000);
           await delay(backoff);
           continue;
        } else break;
      }
    }

    if (batchSuccess) {
       batchEmbeddings.forEach((emb, i) => {
         const originalIndex = batch.indices[i];
         const text = batch.texts[i];
         embeddingCache.set(`${taskType}:${text.trim()}`, emb);
         results[originalIndex] = emb;
       });
    }
  });

  return results;
}

export const filterRelevantPapers = async (
  papers: ArxivPaper[], 
  userQuestions: string[], 
  keywords: string[]
): Promise<ArxivPaper[]> => {
  if (papers.length === 0) return [];

  const userIntentText = `Questions: ${userQuestions.join("\n")}\nKeywords: ${keywords.join(", ")}`;
  const targetVector = await getEmbedding(userIntentText, "RETRIEVAL_QUERY");
  
  if (targetVector.length === 0) return [];

  const paperTexts = papers.map(paper => 
    `Title: ${paper.title}\nAbstract: ${paper.summary}`
  );

  const paperEmbeddings = await getBatchEmbeddings(paperTexts, "RETRIEVAL_DOCUMENT");

  const scoredPapers: ArxivPaper[] = papers.map((paper, index) => {
    const paperVector = paperEmbeddings[index];
    let score = 0;
    if (paperVector && paperVector.length > 0) score = cosineSimilarity(targetVector, paperVector);
    return { ...paper, relevanceScore: score };
  });

  const relevantPapers = scoredPapers
    .filter(p => (p.relevanceScore || 0) >= 0.48)
    .sort((a, b) => (b.relevanceScore || 0) - (a.relevanceScore || 0))
    .slice(0, 20);

  return relevantPapers;
};

interface SimplePdf {
  uri: string;
  pages: string[];
}

export const findRelevantPages = async (
  pdfs: SimplePdf[], 
  userGoal: string, 
  generatedQueries: string[]
): Promise<{ pdfUri: string, pageIndex: number, text: string, score: number }[]> => {
  const masterQuery = `${userGoal}\n${generatedQueries.join("\n")}`;
  const queryVector = await getEmbedding(masterQuery, "RETRIEVAL_QUERY");
  
  if (queryVector.length === 0) return [];

  const initialRelevantPages: { pdfUri: string, pageIndex: number, text: string, score: number }[] = [];
  const allPageTexts: string[] = [];
  const pageMetadata: { pdfUri: string, pageIndex: number, text: string }[] = [];

  for (const pdf of pdfs) {
    for (let i = 0; i < pdf.pages.length; i++) {
       const pageText = pdf.pages[i];
       if (!pageText || pageText.length < 50) continue;
       allPageTexts.push(pageText);
       pageMetadata.push({ pdfUri: pdf.uri, pageIndex: i, text: pageText });
    }
  }

  if (allPageTexts.length === 0) return [];

  const pageEmbeddings = await getBatchEmbeddings(allPageTexts, "RETRIEVAL_DOCUMENT");

  for (let i = 0; i < pageEmbeddings.length; i++) {
    const pageVector = pageEmbeddings[i];
    if (pageVector && pageVector.length > 0) {
      const score = cosineSimilarity(queryVector, pageVector);
      if (score > 0.20) initialRelevantPages.push({ ...pageMetadata[i], score });
    }
  }

  const expandedRelevantPages = [...initialRelevantPages];
  const pagesByPdf = new Map<string, typeof initialRelevantPages>();
  initialRelevantPages.forEach(p => {
    if (!pagesByPdf.has(p.pdfUri)) pagesByPdf.set(p.pdfUri, []);
    pagesByPdf.get(p.pdfUri)?.push(p);
  });

  pagesByPdf.forEach((pdfPages, uri) => {
    pdfPages.sort((a, b) => a.pageIndex - b.pageIndex);
    for (let i = 0; i < pdfPages.length - 1; i++) {
      const current = pdfPages[i];
      const next = pdfPages[i + 1];
      if (next.pageIndex - current.pageIndex === 2) {
        const missingIndex = current.pageIndex + 1;
        const sourcePdf = pdfs.find(p => p.uri === uri);
        if (sourcePdf && sourcePdf.pages[missingIndex]) {
          expandedRelevantPages.push({
            pdfUri: uri,
            pageIndex: missingIndex,
            text: sourcePdf.pages[missingIndex],
            score: (current.score + next.score) / 2
          });
        }
      }
    }
  });

  expandedRelevantPages.sort((a, b) => {
    if (a.pdfUri !== b.pdfUri) return a.pdfUri.localeCompare(b.pdfUri);
    return a.pageIndex - b.pageIndex;
  });

  return expandedRelevantPages;
};

export const extractNotesFromPages = async (
  relevantPages: { pdfUri: string, pageIndex: number, text: string }[],
  userQuestions: string,
  paperTitle?: string,
  paperAbstract?: string,
  referenceList?: string[], 
  onStreamUpdate?: (notes: DeepResearchNote[]) => void
): Promise<DeepResearchNote[]> => {
  if (!ai && !OPENAI_API_KEY) {
    console.warn('[Note Extraction] No AI services available - cannot extract notes');
    return [];
  }

  const BATCH_SIZE = 8; 
  const CONCURRENCY = 3;

  const batches: { pdfUri: string, pageIndex: number, text: string }[][] = [];
  for (let i = 0; i < relevantPages.length; i += BATCH_SIZE) {
    batches.push(relevantPages.slice(i, i + BATCH_SIZE));
  }
  
  let batchCount = 0;

  const processBatch = async (batch: typeof relevantPages) => {
    const batchId = ++batchCount;
    await delay(Math.random() * 2000);

    const contextText = batch.map(p => {
      const pageNum = p.pageIndex + 1;
      return `==Page ${pageNum} (Source: ${p.pdfUri})==\n${p.text}\n==Page ${pageNum}==`;
    }).join("\n\n");

    const referencesText = referenceList && referenceList.length > 0 
      ? `REFERENCE LIST (Use these to resolve citations found in the text) ##### :\n${referenceList.join('\n')}\n\n`
      : "";

    const paperContextText = (paperTitle || paperAbstract) 
      ? `######## PAPER CONTEXT:
Title: ${paperTitle || "Unknown"}
Abstract: ${paperAbstract || "Not available"}\n\n ############`
      : "";

    const prompt = `
      ${referencesText}
     ${paperContextText}
      You are a PhD Research Assistant.
      User's Specific Questions: "${userQuestions}"

      ### INSTRUCTION ###
      Below are pages from PDF documents.
      Your task is to extract meaningful insights and direct quotes that answer the user's questions.

      ### RULES ###
      1. **Strict Relevance**: Only extract if it DIRECTLY answers a question. Ignore general background unless requested.
      2. **Contextual Justification**: You must justify WHY you selected this quote. Additionally, explain the surrounding context on the page where the quote was found (e.g., in which section it appears, what was being discussed immediately before or after) to provide a fuller explanation of its significance within the paper.
      3. **Scoring**: Rate the relevance of this note (0.0 to 1.0).
      4. **Citation Extraction**: If the extracted quote contains a citation marker (e.g., [1], (Smith 2020)), you MUST extract it and match it to the provided Reference List above. Return the inline marker and the full reference text.
      5. **Schema**: Return a valid JSON ARRAY of objects.
      
      Output JSON Format:
      {
        "notes": [
          {
            "quote": "text...",
            "justification": "Detailed explanation of why this was picked and the context of the surrounding text on the page...",
            "relatedQuestion": "q...",
            "pageNumber": 12,
            "relevanceScore": 0.95,
            "citations": [ { "inline": "[1]", "full": "..." } ]
          }
        ]
      }

      Input Pages:
      ${contextText}

      ### INSTRUCTION ###
      Below are pages from PDF documents.
      Your task is to extract meaningful insights and direct quotes that answer the user's questions.

      ### RULES ###
      1. **Strict Relevance**: Only extract if it DIRECTLY answers a question. Ignore general background unless requested.
      2. **Contextual Justification**: You must justify WHY you selected this quote. Additionally, explain the surrounding context on the page where the quote was found (e.g., in which section it appears, what was being discussed immediately before/after) to provide a fuller explanation of its significance within the paper.
      3. **Scoring**: Rate the relevance of this note (0.0 to 1.0).
      4. **Citation Extraction**: If the extracted quote contains a citation marker (e.g., [1], (Smith 2020)), you MUST extract it and match it to the provided Reference List above. Return the inline marker and the full reference text.
      5. **Schema**: Return a valid JSON ARRAY of objects.
      
      Output JSON Format:
      {
        "notes": [
          {
            "quote": "text...",
            "justification": "Detailed explanation of why this was picked and the context of the surrounding text on the page...",
            "relatedQuestion": "q...",
            "pageNumber": 12,
            "relevanceScore": 0.95,
            "citations": [ { "inline": "[1]", "full": "..." } ]
          }
        ]
      }

      The User's Specific Questions to answer: "${userQuestions}"

    `;

    let batchNotes: any[] = [];
    let success = false;

    for(let attempt = 0; attempt < 3; attempt++) {
        try {
            if (!ai) {
              console.warn('[Note Extraction] Gemini AI not available - using fallback OpenAI');
              throw new Error('Gemini AI not initialized');
            }
            
            const response = await ai.models.generateContent({
                model: "gemini-2.5-flash",
                contents: prompt,
                config: { responseMimeType: "application/json" }
            });
            const text = response.text;
            if (text) {
                const cleanText = cleanJson(text);
                const parsed = JSON.parse(cleanText);
                batchNotes = Array.isArray(parsed) ? parsed : (parsed.notes || []);
                success = true;
                break;
            }
        } catch (error: any) {
            if(error.status === 429) {
                await delay(Math.pow(2, attempt) * 1500);
                continue;
            } else break;
        }
    }

    if (!success) {
      try {
        const parsed = await callOpenAI(prompt);
        batchNotes = Array.isArray(parsed) ? parsed : (parsed.notes || []);
        success = true;
      } catch (err) {}
    }

    if (success && batchNotes.length > 0) {
      const normalizedNotes = batchNotes.map((note: any) => {
        const matchingPage = batch.find(p => (p.pageIndex + 1) === note.pageNumber);
        return {
          quote: note.quote || note.note || "", 
          justification: note.justification || "Relevant.",
          relatedQuestion: note.relatedQuestion || "General",
          pageNumber: note.pageNumber,
          pdfUri: matchingPage ? matchingPage.pdfUri : (batch[0]?.pdfUri || note.pdfUri),
          relevanceScore: typeof note.relevanceScore === 'number' ? note.relevanceScore : 0.75,
          citations: Array.isArray(note.citations) ? note.citations : []
        };
      });

      if (onStreamUpdate) onStreamUpdate(normalizedNotes);
      return normalizedNotes as DeepResearchNote[];
    }
    return [];
  };

  const results = await asyncPool(CONCURRENCY, batches, processBatch);
  return results.flat().filter(n => n !== null);
};

const fetchSingleSearch = async (query: string): Promise<any[]> => {
  if (!GOOGLE_SEARCH_KEY || !GOOGLE_SEARCH_CX) return [];
  try {
    let cleanQuery = query.replace(/:pdf/gi, '').replace(/filetype:pdf/gi, '').trim();
    if (!cleanQuery) cleanQuery = query;

    const params = new URLSearchParams({
      key: GOOGLE_SEARCH_KEY,
      cx: GOOGLE_SEARCH_CX,
      q: cleanQuery,
      fileType: "pdf",
      num: "10",
    });

    const url = `https://www.googleapis.com/customsearch/v1?${params.toString()}`;
    const response = await fetch(url);
    if (!response.ok) return [];
    const data = await response.json();
    return data.items || [];
  } catch (e) {
    return [];
  }
};

export const performSearch = async (query: string): Promise<SearchResultData> => {
  if (!GOOGLE_SEARCH_CX) throw new Error("Missing CX ID.");

  try {
    const aiVariations = await generateSearchVariations(query);
    const allQueries = Array.from(new Set([query, ...aiVariations]));
    const resultsArrays = await Promise.all(allQueries.map(q => fetchSingleSearch(q)));
    const uniqueSourcesMap = new Map<string, SearchSource>();

    resultsArrays.flat().forEach((item: any) => {
      const link = item.link || "";
      if (link && link.toLowerCase().includes("pdf")) {
        if (!uniqueSourcesMap.has(link)) {
          uniqueSourcesMap.set(link, {
            title: item.title || "Untitled PDF",
            uri: link,
            snippet: item.snippet || "No description."
          });
        }
      }
    });

    const sources = Array.from(uniqueSourcesMap.values());
    return {
      summary: sources.length === 0 ? `No PDF results found.` : `Found ${sources.length} unique PDF sources.`,
      sources,
      allQueries
    };
  } catch (error) {
    console.error("Search Error:", error);
    throw error;
  }
};
